import { Injectable, BadRequestException } from '@nestjs/common';
import { PrismaService } from '../prisma.service';
import OpenAI from 'openai';

@Injectable()
export class AiService {
  constructor(private prisma: PrismaService) {}

  // 1. è·å–æ‰€æœ‰é…ç½®å¥½çš„ AI æ¸ é“
  async findAllProviders() {
    // ä¸ºäº†å®‰å…¨ï¼Œä¸è¿”å›å®Œæ•´çš„ keyï¼Œåªè¿”å›éƒ¨åˆ†ä¿¡æ¯
    const providers = await this.prisma.ai_providers.findMany({
      orderBy: { id: 'asc' }
    });
    return providers.map(p => ({
      ...p,
      api_key: p.api_key ? 'sk-****' + p.api_key.slice(-4) : '', // æ©ç å¤„ç†
    }));
  }

  // 2. æ·»åŠ /æ›´æ–° AI æ¸ é“
  async saveProvider(data: any) {
    // ç®€å•çš„å•ç”¨æˆ·é€»è¾‘ï¼šæš‚æ—¶ä¸åšå¤æ‚çš„ç”¨æˆ·é‰´æƒï¼Œé»˜è®¤ userId å…ˆç©ºç€æˆ–è€…å¡«ä¸ªå›ºå®šçš„
    // è¿™é‡Œçš„ data åº”è¯¥åŒ…å« name, provider, baseUrl, apiKey, models
    
    // ä¹Ÿå°±æ˜¯ CreateAiProviderDtoï¼Œä¸ºäº†ç®€ä¾¿ç›´æ¥å†™é€»è¾‘
    return this.prisma.ai_providers.create({
      data: {
        name: data.name,
        provider: data.provider, // 'openai', 'deepseek', 'ollama'
        base_url: data.baseUrl,
        api_key: data.apiKey,
        models: data.models || [], // JSON æ•°ç»„ ['gpt-4', 'deepseek-chat']
        is_active: true,
        // user_id: ... (å¤šç”¨æˆ·ç³»ç»Ÿéœ€è¦)
      }
    });
  }

  // 3. åˆ é™¤æ¸ é“
  async deleteProvider(id: number) {
    // æ³¨æ„ id ç±»å‹ï¼Œæ ¹æ® schema å¯èƒ½æ˜¯ int æˆ– uuidï¼Œä¹‹å‰ SQL æ˜¯ SERIAL (int)
    return this.prisma.ai_providers.delete({ where: { id: Number(id) } });
  }

  // ğŸ”¥ æ ¸å¿ƒï¼šè°ƒç”¨ AI ç”Ÿæˆæ–‡æœ¬
  async generateText(prompt: string, context: string, providerId: number) {
    // 1. è·å–é…ç½®
    const providerConfig = await this.prisma.ai_providers.findUnique({
      where: { id: Number(providerId) }
    });

    if (!providerConfig) throw new BadRequestException('AI Channel not found');

    // 2. åˆå§‹åŒ– OpenAI Client (å…¼å®¹æ¨¡å¼)
    const client = new OpenAI({
      apiKey: providerConfig.api_key || 'empty', // Ollama ä¸éœ€è¦ key ä½† SDK éœ€è¦éç©º
      baseURL: providerConfig.base_url || 'https://api.openai.com/v1',
    });

    // 3. é€‰æ‹©æ¨¡å‹ (é»˜è®¤å–åˆ—è¡¨ç¬¬ä¸€ä¸ªï¼Œæˆ–è€…å‰ç«¯ä¼ )
    // è¿™é‡Œçš„ç±»å‹è½¬æ¢æ˜¯ä¸ªå‘ï¼Œprisma json å‡ºæ¥æ˜¯ any
    const models = providerConfig.models as string[];
    const model = models && models.length > 0 ? models[0] : 'gpt-3.5-turbo';

    try {
      const response = await client.chat.completions.create({
        model: model,
        messages: [
          { role: 'system', content: 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å°è¯´å†™ä½œåŠ©æ‰‹ã€‚è¯·æ ¹æ®ç”¨æˆ·çš„ä¸Šä¸‹æ–‡ç»­å†™æˆ–æ¶¦è‰²å†…å®¹ã€‚åªè¿”å›ç»“æœï¼Œä¸è¦å•°å—¦ã€‚' },
          { role: 'user', content: `ä¸Šä¸‹æ–‡ï¼š\n${context}\n\nè¦æ±‚ï¼š${prompt}` }
        ],
        temperature: 0.8,
      });

      return { 
        result: response.choices[0]?.message?.content || '',
        model: model 
      };
    } catch (error) {
      console.error('AI Call Failed:', error);
      throw new BadRequestException(`AIè°ƒç”¨å¤±è´¥: ${error.message}`);
    }
  }
}